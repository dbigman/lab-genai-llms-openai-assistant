{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB GenAI - LLMs - OpenAI Assistant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an assistant to answer a topic of your choosing:\n",
    " - Upload a file of your interest\n",
    " - Add Instructions to the prompt\n",
    " - Use the assistant in Playground mode\n",
    "\n",
    " https://platform.openai.com/playground/assistants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from icecream import ic\n",
    "from openai import OpenAI\n",
    "from tabulate import tabulate\n",
    "\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# get OpenAI API key\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "\n",
    "client = openai.OpenAI(api_key=openai_api_key)\n",
    "\n",
    "\n",
    "# # List all assistants\n",
    "# assistants = client.beta.assistants.list()\n",
    "\n",
    "# # Print available assistant IDs\n",
    "# for assistant in assistants.data:\n",
    "#     print(f\"Name: {assistant.name}, ID: {assistant.id}\")\n",
    "\n",
    "\n",
    "assistant_id = \"asst_H1kg2cDQaRANsulU11HNVC8e\"\n",
    "\n",
    "# Create a thread for the conversation\n",
    "thread = client.beta.threads.create()\n",
    "\n",
    "\n",
    "# Send a message to the assistant\n",
    "message = client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=\"Hello, what is project management?\"\n",
    ")\n",
    "\n",
    "# Run the assistant on the created thread\n",
    "run = client.beta.threads.runs.create(\n",
    "    thread_id=thread.id,\n",
    "    assistant_id=assistant_id\n",
    ")\n",
    "\n",
    "# Wait for completion (polling)\n",
    "import time\n",
    "while run.status not in [\"completed\", \"failed\"]:\n",
    "    time.sleep(1)\n",
    "    run = client.beta.threads.runs.retrieve(thread_id=thread.id, run_id=run.id)\n",
    "\n",
    "# Get the response messages\n",
    "messages = client.beta.threads.messages.list(thread_id=thread.id)\n",
    "for msg in messages.data:\n",
    "    if msg.role == \"assistant\":\n",
    "        # Extract the text content\n",
    "        response_text = msg.content[0].text.value  # Extract the response text\n",
    "        print(response_text)  # Print or store the response\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Manager Assistant\n",
    "\n",
    "**Thread ID:** `thread_VQReOCA07rmdhvq1x8HEgANM`  \n",
    "**Tokens Used:** `18076`\n",
    "\n",
    "## Overview\n",
    "Project management is the process of guiding a project from its beginning through its performance to its closure. It encompasses five sets of processes:\n",
    "\n",
    "## 1. Initiating Processes\n",
    "These involve:\n",
    "- Clarifying the business need\n",
    "- Defining high-level expectations\n",
    "- Establishing resource budgets\n",
    "- Identifying audiences that may play a role in the project\n",
    "\n",
    "## 2. Planning Processes\n",
    "These processes detail:\n",
    "- Project scope\n",
    "- Time frames\n",
    "- Resources and risks\n",
    "- Approaches to project communications, quality, and external purchases of goods and services\n",
    "\n",
    "## 3. Executing Processes\n",
    "This involves:\n",
    "- Establishing and managing the project team\n",
    "- Communicating with and managing project audiences\n",
    "- Implementing project plans\n",
    "\n",
    "## 4. Monitoring and Controlling Processes\n",
    "These processes:\n",
    "- Track performance\n",
    "- Take necessary actions to ensure project plans are successfully implemented\n",
    "- Ensure the desired results are achieved\n",
    "\n",
    "## 5. Closing Processes\n",
    "These involve:\n",
    "- Ending all project activities\n",
    "\n",
    "## Project Life Cycle Stages\n",
    "These processes help support a project through the four stages of its life cycle:\n",
    "1. **Starting the project**\n",
    "2. **Organizing and preparing**\n",
    "3. **Carrying out the work**\n",
    "4. **Closing out the project**\n",
    "\n",
    "---\n",
    "\n",
    "### References\n",
    "[1] [2] [3]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Talk to your assistant via the API\n",
    "\n",
    "https://platform.openai.com/docs/assistants/overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from icecream import ic\n",
    "from openai import OpenAI\n",
    "from tabulate import tabulate\n",
    "\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# get OpenAI API key\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "\n",
    "client = openai.OpenAI(api_key=openai_api_key)\n",
    "\n",
    "\n",
    "\n",
    "assistant_id = \"asst_H1kg2cDQaRANsulU11HNVC8e\"\n",
    "\n",
    "# Create a thread for the conversation\n",
    "thread = client.beta.threads.create()\n",
    "\n",
    "# Send a message to the assistant\n",
    "message = client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=\"Hello, what is a common mistake in project management?\"\n",
    ")\n",
    "\n",
    "# Run the assistant on the created thread\n",
    "run = client.beta.threads.runs.create(\n",
    "    thread_id=thread.id,\n",
    "    assistant_id=assistant_id\n",
    ")\n",
    "\n",
    "# Wait for completion (polling)\n",
    "import time\n",
    "while run.status not in [\"completed\", \"failed\"]:\n",
    "    time.sleep(1)\n",
    "    run = client.beta.threads.runs.retrieve(thread_id=thread.id, run_id=run.id)\n",
    "\n",
    "# Get the response messages\n",
    "messages = client.beta.threads.messages.list(thread_id=thread.id)\n",
    "for msg in messages.data:\n",
    "    if msg.role == \"assistant\":\n",
    "        # Extract the text content\n",
    "        response_text = msg.content[0].text.value  # Extract the response text\n",
    "        print(response_text)  # Print or store the response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an assistant that will call a weather API, given the user's answer and return the proper answer.\n",
    "\n",
    "See the documentation of the weather API here: https://open-meteo.com/en/docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-09 16:50:13,591 - INFO - HTTP Request: GET https://api.openai.com/v1/assistants \"HTTP/1.1 200 OK\"\n",
      "2025-02-09 16:50:13,615 - INFO - Using existing assistant: asst_3eXOUHpUAs92LzUgoYleC558\n",
      "2025-02-09 16:50:13,886 - INFO - HTTP Request: POST https://api.openai.com/v1/threads \"HTTP/1.1 200 OK\"\n",
      "2025-02-09 16:50:13,957 - INFO - Created thread with ID: thread_yAPgYm8v7W9INH7eQK9VhNCv\n",
      "2025-02-09 16:50:14,308 - INFO - HTTP Request: POST https://api.openai.com/v1/threads/thread_yAPgYm8v7W9INH7eQK9VhNCv/messages \"HTTP/1.1 200 OK\"\n",
      "2025-02-09 16:50:14,379 - INFO - Sent user message: 'What's the weather like in Berlin?'\n",
      "2025-02-09 16:50:15,268 - INFO - HTTP Request: POST https://api.openai.com/v1/threads/thread_yAPgYm8v7W9INH7eQK9VhNCv/runs \"HTTP/1.1 200 OK\"\n",
      "2025-02-09 16:50:15,270 - INFO - Started assistant run: run_mdKOlP67cgVsFxIBWkpcTMNg\n",
      "2025-02-09 16:50:15,641 - INFO - HTTP Request: GET https://api.openai.com/v1/threads/thread_yAPgYm8v7W9INH7eQK9VhNCv/runs/run_mdKOlP67cgVsFxIBWkpcTMNg \"HTTP/1.1 200 OK\"\n",
      "2025-02-09 16:50:17,045 - INFO - HTTP Request: GET https://api.openai.com/v1/threads/thread_yAPgYm8v7W9INH7eQK9VhNCv/runs/run_mdKOlP67cgVsFxIBWkpcTMNg \"HTTP/1.1 200 OK\"\n",
      "2025-02-09 16:50:18,480 - INFO - HTTP Request: GET https://api.openai.com/v1/threads/thread_yAPgYm8v7W9INH7eQK9VhNCv/runs/run_mdKOlP67cgVsFxIBWkpcTMNg \"HTTP/1.1 200 OK\"\n",
      "2025-02-09 16:50:18,544 - INFO - Assistant run status: requires_action. Exiting wait loop.\n",
      "2025-02-09 16:50:18,545 - INFO - Assistant requires action: function execution needed.\n",
      "2025-02-09 16:50:18,545 - INFO - Executing get_weather_forecast for lat=52.52, lon=13.405\n",
      "2025-02-09 16:50:18,546 - INFO - Fetching weather data for lat=52.52, lon=13.405\n",
      "2025-02-09 16:50:20,096 - INFO - HTTP Request: POST https://api.openai.com/v1/threads/thread_yAPgYm8v7W9INH7eQK9VhNCv/runs/run_mdKOlP67cgVsFxIBWkpcTMNg/submit_tool_outputs \"HTTP/1.1 200 OK\"\n",
      "2025-02-09 16:50:20,174 - INFO - Submitted tool outputs to assistant.\n",
      "2025-02-09 16:50:20,445 - INFO - HTTP Request: GET https://api.openai.com/v1/threads/thread_yAPgYm8v7W9INH7eQK9VhNCv/runs/run_mdKOlP67cgVsFxIBWkpcTMNg \"HTTP/1.1 200 OK\"\n",
      "2025-02-09 16:50:21,839 - INFO - HTTP Request: GET https://api.openai.com/v1/threads/thread_yAPgYm8v7W9INH7eQK9VhNCv/runs/run_mdKOlP67cgVsFxIBWkpcTMNg \"HTTP/1.1 200 OK\"\n",
      "2025-02-09 16:50:23,210 - INFO - HTTP Request: GET https://api.openai.com/v1/threads/thread_yAPgYm8v7W9INH7eQK9VhNCv/runs/run_mdKOlP67cgVsFxIBWkpcTMNg \"HTTP/1.1 200 OK\"\n",
      "2025-02-09 16:50:24,629 - INFO - HTTP Request: GET https://api.openai.com/v1/threads/thread_yAPgYm8v7W9INH7eQK9VhNCv/runs/run_mdKOlP67cgVsFxIBWkpcTMNg \"HTTP/1.1 200 OK\"\n",
      "2025-02-09 16:50:26,046 - INFO - HTTP Request: GET https://api.openai.com/v1/threads/thread_yAPgYm8v7W9INH7eQK9VhNCv/runs/run_mdKOlP67cgVsFxIBWkpcTMNg \"HTTP/1.1 200 OK\"\n",
      "2025-02-09 16:50:27,465 - INFO - HTTP Request: GET https://api.openai.com/v1/threads/thread_yAPgYm8v7W9INH7eQK9VhNCv/runs/run_mdKOlP67cgVsFxIBWkpcTMNg \"HTTP/1.1 200 OK\"\n",
      "2025-02-09 16:50:27,467 - INFO - Assistant run completed after tool outputs submission.\n",
      "2025-02-09 16:50:28,740 - INFO - HTTP Request: GET https://api.openai.com/v1/threads/thread_yAPgYm8v7W9INH7eQK9VhNCv/messages \"HTTP/1.1 200 OK\"\n",
      "2025-02-09 16:50:28,809 - INFO - Assistant response: The current temperature in Berlin is approximately 0°C. Here's an overview of the upcoming temperature:\n",
      "\n",
      "- **Morning**: Temperatures starting around -1°C, warming up to about 2°C by midday.\n",
      "- **Afternoon**: Temperatures peaking at around 3.7°C.\n",
      "- **Evening**: Cooling down to around 0.9°C.\n",
      "\n",
      "The temperature will be slightly below freezing in the early morning and will rise slightly during the day before dropping again in the evening.\n",
      "2025-02-09 16:50:28,810 - INFO - Assistant response: What's the weather like in Berlin?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: The current temperature in Berlin is approximately 0°C. Here's an overview of the upcoming temperature:\n",
      "\n",
      "- **Morning**: Temperatures starting around -1°C, warming up to about 2°C by midday.\n",
      "- **Afternoon**: Temperatures peaking at around 3.7°C.\n",
      "- **Evening**: Cooling down to around 0.9°C.\n",
      "\n",
      "The temperature will be slightly below freezing in the early morning and will rise slightly during the day before dropping again in the evening.\n",
      "Assistant: What's the weather like in Berlin?\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import requests\n",
    "import os\n",
    "import time\n",
    "import logging\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "\n",
    "# OpenAI client\n",
    "client = openai.OpenAI(api_key=api_key)\n",
    "\n",
    "# Function to get weather forecast\n",
    "def get_weather_forecast(latitude, longitude):\n",
    "    logging.info(f\"Fetching weather data for lat={latitude}, lon={longitude}\")\n",
    "    base_url = \"https://api.open-meteo.com/v1/forecast\"\n",
    "    params = {\n",
    "        \"latitude\": latitude,\n",
    "        \"longitude\": longitude,\n",
    "        \"hourly\": \"temperature_2m\"\n",
    "    }\n",
    "    response = requests.get(base_url, params=params)\n",
    "    return response.json()\n",
    "\n",
    "# Create or retrieve assistant\n",
    "assistants = client.beta.assistants.list()\n",
    "assistant_id = None\n",
    "\n",
    "for assistant in assistants.data:\n",
    "    if assistant.name == \"Weather Assistant\":\n",
    "        assistant_id = assistant.id\n",
    "        logging.info(f\"Using existing assistant: {assistant_id}\")\n",
    "        break\n",
    "\n",
    "if not assistant_id:\n",
    "    assistant = client.beta.assistants.create(\n",
    "        name=\"Weather Assistant\",\n",
    "        instructions=\"You provide weather forecasts when given a location. Use the function to fetch live weather data.\",\n",
    "        model=\"gpt-4o\",\n",
    "        tools=[{\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"get_weather_forecast\",\n",
    "                \"description\": \"Get the weather forecast for a specific location.\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"latitude\": {\n",
    "                            \"type\": \"number\",\n",
    "                            \"description\": \"Latitude of the location\"\n",
    "                        },\n",
    "                        \"longitude\": {\n",
    "                            \"type\": \"number\",\n",
    "                            \"description\": \"Longitude of the location\"\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": [\"latitude\", \"longitude\"]\n",
    "                }\n",
    "            }\n",
    "        }]\n",
    "    )\n",
    "    assistant_id = assistant.id\n",
    "    logging.info(f\"Created new assistant with ID: {assistant_id}\")\n",
    "\n",
    "# Create a conversation thread\n",
    "thread = client.beta.threads.create()\n",
    "logging.info(f\"Created thread with ID: {thread.id}\")\n",
    "\n",
    "# User asks for weather\n",
    "user_message = client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=\"What's the weather like in Berlin?\"\n",
    ")\n",
    "logging.info(\"Sent user message: 'What's the weather like in Berlin?'\")\n",
    "\n",
    "# Run the assistant on the thread\n",
    "run = client.beta.threads.runs.create(\n",
    "    thread_id=thread.id,\n",
    "    assistant_id=assistant_id\n",
    ")\n",
    "logging.info(f\"Started assistant run: {run.id}\")\n",
    "\n",
    "# Wait for the assistant run to reach a terminal state or require action\n",
    "while True:\n",
    "    run = client.beta.threads.runs.retrieve(thread_id=thread.id, run_id=run.id)\n",
    "    if run.status in (\"completed\", \"requires_action\"):\n",
    "        logging.info(f\"Assistant run status: {run.status}. Exiting wait loop.\")\n",
    "        break\n",
    "    time.sleep(1)\n",
    "\n",
    "# If the assistant requires action (e.g., a function call), process it\n",
    "if run.status == \"requires_action\":\n",
    "    logging.info(\"Assistant requires action: function execution needed.\")\n",
    "\n",
    "    # Extract function call details and prepare outputs\n",
    "    tool_outputs = []\n",
    "    for action in run.required_action.submit_tool_outputs.tool_calls:\n",
    "        if action.function.name == \"get_weather_forecast\":\n",
    "            try:\n",
    "                args = json.loads(action.function.arguments)\n",
    "                latitude = args.get(\"latitude\")\n",
    "                longitude = args.get(\"longitude\")\n",
    "                if latitude is None or longitude is None:\n",
    "                    raise ValueError(\"Missing 'latitude' or 'longitude' in function arguments.\")\n",
    "            except (json.JSONDecodeError, ValueError, KeyError) as e:\n",
    "                logging.error(f\"Error parsing function call details for action {action.id}: {e}\")\n",
    "                continue\n",
    "\n",
    "            logging.info(f\"Executing get_weather_forecast for lat={latitude}, lon={longitude}\")\n",
    "            weather_data = get_weather_forecast(latitude, longitude)\n",
    "\n",
    "            tool_outputs.append({\n",
    "                \"tool_call_id\": action.id,\n",
    "                \"output\": json.dumps(weather_data)  # Must be a JSON string\n",
    "            })\n",
    "\n",
    "    # Submit the function results back to the assistant\n",
    "    client.beta.threads.runs.submit_tool_outputs(\n",
    "        thread_id=thread.id,\n",
    "        run_id=run.id,\n",
    "        tool_outputs=tool_outputs\n",
    "    )\n",
    "    logging.info(\"Submitted tool outputs to assistant.\")\n",
    "\n",
    "    # After submitting tool outputs, wait until the run is completed\n",
    "    while True:\n",
    "        run = client.beta.threads.runs.retrieve(thread_id=thread.id, run_id=run.id)\n",
    "        if run.status == \"completed\":\n",
    "            logging.info(\"Assistant run completed after tool outputs submission.\")\n",
    "            break\n",
    "        time.sleep(1)\n",
    "\n",
    "# Optional: Give the assistant a moment to finalize processing\n",
    "time.sleep(1)\n",
    "\n",
    "# Retrieve and print the assistant's response\n",
    "messages = client.beta.threads.messages.list(thread_id=thread.id)\n",
    "for msg in messages.data:\n",
    "    # Assumes the response message structure includes a text value\n",
    "    try:\n",
    "        response_text = msg.content[0].text.value\n",
    "    except (IndexError, AttributeError, KeyError):\n",
    "        response_text = \"<No text response available>\"\n",
    "    logging.info(f\"Assistant response: {response_text}\")\n",
    "    print(f\"Assistant: {response_text}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If you want to, there is a hint here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenAI Chatbots / Assistants have a way to respond in json format. \n",
    "\n",
    "Explore the function calling functionality"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
